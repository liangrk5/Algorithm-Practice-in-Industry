name: Daily ArXiv Paper Filtering & Notifications

on:
  schedule:
    # 运行在每天UTC时间10:00 (北京时间18:00)
    # 如需调整为北京时间10:00，请将cron修改为 '0 2 * * *' (UTC+8)
    - cron: '0 2 * * *'
  workflow_dispatch:  # 允许手动触发

jobs:
  fetch-and-filter:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v2
      
      - name: Set up Python 3.9
        uses: actions/setup-python@v2
        with:
          python-version: '3.9'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests tqdm google-generativeai openai
          
      - name: Cache arxiv.json
        uses: actions/cache@v2
        with:
          path: arxiv.json
          key: ${{ runner.os }}-arxiv-data-${{ github.run_id }}
          restore-keys: |
            ${{ runner.os }}-arxiv-data-
      
      - name: Run arXiv crawler with Gemini filtering
        env:
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
          MODEL_TYPE: ${{ secrets.MODEL_TYPE || 'Gemini' }}
          QUERY: ${{ secrets.ARXIV_QUERY || 'cs.IR,cs.AI,cs.CL' }}
          LIMITS: ${{ secrets.ARXIV_LIMITS || '50' }}
          SERVERCHAN_API_KEY: ${{ secrets.SERVERCHAN_API_KEY }}
          FEISHU_URL: ${{ secrets.FEISHU_URL }}
          DEEPSEEK_API_KEY: ${{ secrets.DEEPSEEK_API_KEY }}
          CAIYUN_TOKEN: ${{ secrets.CAIYUN_TOKEN }}
        run: |
          # 检查arxiv.json是否存在，如果不存在则创建
          if [ ! -f "arxiv.json" ]; then
            echo "[]" > arxiv.json
          fi
          
          # 运行主程序
          python arxiv.py
          
      - name: Save updated arxiv.json
        if: always()  # 即使上一步失败也保存结果
        uses: actions/upload-artifact@v2
        with:
          name: arxiv-data
          path: arxiv.json
          retention-days: 30